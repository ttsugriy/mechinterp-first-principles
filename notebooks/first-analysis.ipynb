{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Your First Mechanistic Interpretability Analysis\n",
        "\n",
        "A complete walkthrough from question to understanding.\n",
        "\n",
        "**Companion notebook for [First Principles of Mechanistic Interpretability](https://ttsugriy.github.io/mechinterp-first-principles/first-analysis.html)**\n",
        "\n",
        "---\n",
        "\n",
        "## What You'll Do\n",
        "\n",
        "1. Define a simple behavior to analyze\n",
        "2. Verify the model exhibits the behavior\n",
        "3. Use attribution to find relevant components\n",
        "4. Validate with patching\n",
        "5. Interpret what you found\n",
        "\n",
        "**Prerequisites:** Make sure you have a GPU runtime (Runtime â†’ Change runtime type â†’ T4 GPU)"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0: Setup"
      ],
      "metadata": {
        "id": "setup-header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "# Install libraries\n",
        "!pip install -q transformer-lens einops jaxtyping circuitsvis plotly\n",
        "\n",
        "import torch\n",
        "import transformer_lens as tl\n",
        "from transformer_lens import utils\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Load GPT-2 Small\n",
        "model = tl.HookedTransformer.from_pretrained(\"gpt2-small\")\n",
        "print(f\"Loaded {model.cfg.model_name}: {model.cfg.n_layers} layers, {model.cfg.n_heads} heads\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## The Behavior: Sentiment-Influenced Completion\n",
        "\n",
        "We'll analyze a simple but interesting behavior:\n",
        "\n",
        "> When given \"I love this movie because it is\", GPT-2 predicts positive words like \"great\" or \"good\".\n",
        "> When given \"I hate this movie because it is\", GPT-2 predicts negative words like \"bad\" or \"terrible\".\n",
        "\n",
        "**The question**: How does the model know to predict positive vs negative words? Which components read the sentiment word (\"love\" vs \"hate\") and influence the prediction?"
      ],
      "metadata": {
        "id": "behavior"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Verify the Behavior Exists\n",
        "\n",
        "**Never skip this step.** Before analyzing a behavior, confirm the model actually exhibits it."
      ],
      "metadata": {
        "id": "step1-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_predictions(model, prompt: str, k: int = 5) -> list[tuple[str, float, float]]:\n",
        "    \"\"\"Get the model's top-k predictions for the next token.\"\"\"\n",
        "    tokens = model.to_tokens(prompt)\n",
        "    logits = model(tokens)\n",
        "    top_logits, top_tokens = logits[0, -1].topk(k)\n",
        "    probs = torch.softmax(logits[0, -1], dim=-1)\n",
        "\n",
        "    return [\n",
        "        (model.tokenizer.decode(token), probs[token].item(), logit.item())\n",
        "        for logit, token in zip(top_logits, top_tokens)\n",
        "    ]\n",
        "\n",
        "# Test positive sentiment\n",
        "print(\"POSITIVE: 'I love this movie because it is'\")\n",
        "for word, prob, logit in get_top_predictions(model, \"I love this movie because it is\"):\n",
        "    print(f\"  {word:15} prob={prob:.3f}  logit={logit:.2f}\")\n",
        "\n",
        "print(\"\\nNEGATIVE: 'I hate this movie because it is'\")\n",
        "for word, prob, logit in get_top_predictions(model, \"I hate this movie because it is\"):\n",
        "    print(f\"  {word:15} prob={prob:.3f}  logit={logit:.2f}\")"
      ],
      "metadata": {
        "id": "step1-top-predictions"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check specific sentiment words\n",
        "def get_token_logit(model, prompt: str, target_word: str) -> float:\n",
        "    \"\"\"Get the logit for a specific target word.\"\"\"\n",
        "    tokens = model.to_tokens(prompt)\n",
        "    logits = model(tokens)\n",
        "    target_token = model.to_single_token(target_word)\n",
        "    return logits[0, -1, target_token].item()\n",
        "\n",
        "# Compare logits for \"great\" and \"bad\"\n",
        "positive_prompt = \"I love this movie because it is\"\n",
        "negative_prompt = \"I hate this movie because it is\"\n",
        "\n",
        "print(\"Logit for 'great':\")\n",
        "print(f\"  After 'love': {get_token_logit(model, positive_prompt, ' great'):.2f}\")\n",
        "print(f\"  After 'hate': {get_token_logit(model, negative_prompt, ' great'):.2f}\")\n",
        "\n",
        "print(\"\\nLogit for 'bad':\")\n",
        "print(f\"  After 'love': {get_token_logit(model, positive_prompt, ' bad'):.2f}\")\n",
        "print(f\"  After 'hate': {get_token_logit(model, negative_prompt, ' bad'):.2f}\")"
      ],
      "metadata": {
        "id": "step1-specific-words"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… **Confirmed!** The model shifts predictions based on sentiment:\n",
        "- \" great\" gets higher logit after \"love\"\n",
        "- \" bad\" gets higher logit after \"hate\""
      ],
      "metadata": {
        "id": "step1-confirmed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 2: Logit Attribution\n",
        "\n",
        "Now let's find *which components* are responsible for this difference.\n",
        "\n",
        "**The idea**: Decompose the final logit into per-component contributions. Which attention heads and MLPs push toward \" great\" in the positive case?"
      ],
      "metadata": {
        "id": "step2-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logit_attribution(model, prompt: str, target_token: str) -> tuple[dict[str, float], float]:\n",
        "    \"\"\"\n",
        "    Compute each component's contribution to the target token's logit.\n",
        "    Returns a dict of component -> contribution, and the total logit.\n",
        "    \"\"\"\n",
        "    target_id = model.to_single_token(target_token)\n",
        "    tokens = model.to_tokens(prompt)\n",
        "\n",
        "    # run_with_cache stores all intermediate activations for analysis\n",
        "    logits, cache = model.run_with_cache(tokens)\n",
        "\n",
        "    # The unembedding column for our target - this is the \"great direction\"\n",
        "    # in residual stream space that, when projected onto, gives the logit\n",
        "    target_dir = model.W_U[:, target_id]\n",
        "\n",
        "    # Measure how much each component points toward our target\n",
        "    # Positive = helps predict it, negative = suppresses it\n",
        "    contributions = {\n",
        "        \"embed\": (cache[\"embed\"][0, -1] @ target_dir).item(),\n",
        "        \"pos_embed\": (cache[\"pos_embed\"][0, -1] @ target_dir).item(),\n",
        "    }\n",
        "\n",
        "    for layer in range(model.cfg.n_layers):\n",
        "        contributions[f\"L{layer}_attn\"] = (cache[\"attn_out\", layer][0, -1] @ target_dir).item()\n",
        "        contributions[f\"L{layer}_mlp\"] = (cache[\"mlp_out\", layer][0, -1] @ target_dir).item()\n",
        "\n",
        "    return contributions, logits[0, -1, target_id].item()"
      ],
      "metadata": {
        "id": "step2-attribution-fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get attribution for \" great\" in positive case\n",
        "pos_attrib, pos_logit = logit_attribution(model, positive_prompt, \" great\")\n",
        "neg_attrib, neg_logit = logit_attribution(model, negative_prompt, \" great\")\n",
        "\n",
        "print(f\"Total logit for ' great': positive={pos_logit:.2f}, negative={neg_logit:.2f}\")\n",
        "print(f\"Difference: {pos_logit - neg_logit:.2f}\")"
      ],
      "metadata": {
        "id": "step2-run-attribution"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare attributions - which components differ most?\n",
        "diff_attrib = {k: pos_attrib[k] - neg_attrib[k] for k in pos_attrib}\n",
        "\n",
        "# Sort by absolute difference\n",
        "sorted_diff = sorted(diff_attrib.items(), key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "print(\"\\nComponents with largest attribution difference (positive - negative):\")\n",
        "print(\"(Positive values â†’ component pushes more toward 'great' in positive case)\")\n",
        "print(\"-\" * 60)\n",
        "for component, diff in sorted_diff[:10]:\n",
        "    print(f\"{component:15} diff={diff:+.3f}  (pos={pos_attrib[component]:.3f}, neg={neg_attrib[component]:.3f})\")"
      ],
      "metadata": {
        "id": "step2-compare"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ’¡ **Key Insight**: The components with the *largest difference* between positive and negative cases are the ones that \"read\" the sentiment and adjust the prediction accordingly."
      ],
      "metadata": {
        "id": "step2-insight"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 3: Visualize the Attribution"
      ],
      "metadata": {
        "id": "step3-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a visualization\n",
        "data = []\n",
        "for layer in range(model.cfg.n_layers):\n",
        "    data.append({\n",
        "        \"layer\": layer,\n",
        "        \"component\": \"attention\",\n",
        "        \"positive\": pos_attrib[f\"L{layer}_attn\"],\n",
        "        \"negative\": neg_attrib[f\"L{layer}_attn\"],\n",
        "        \"diff\": pos_attrib[f\"L{layer}_attn\"] - neg_attrib[f\"L{layer}_attn\"]\n",
        "    })\n",
        "    data.append({\n",
        "        \"layer\": layer,\n",
        "        \"component\": \"mlp\",\n",
        "        \"positive\": pos_attrib[f\"L{layer}_mlp\"],\n",
        "        \"negative\": neg_attrib[f\"L{layer}_mlp\"],\n",
        "        \"diff\": pos_attrib[f\"L{layer}_mlp\"] - neg_attrib[f\"L{layer}_mlp\"]\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Plot the difference\n",
        "fig = px.bar(df, x=\"layer\", y=\"diff\", color=\"component\",\n",
        "             barmode=\"group\",\n",
        "             title=\"Attribution Difference: Positive vs Negative Sentiment\",\n",
        "             labels={\"diff\": \"Contribution difference to 'great'\", \"layer\": \"Layer\"})\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "step3-visualize"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What to look for**: Layers where the bars are tall (large difference) are where the model processes sentiment."
      ],
      "metadata": {
        "id": "step3-interpretation"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 4: Look at Specific Heads\n",
        "\n",
        "The layer-level view is coarse. Let's look at individual attention heads."
      ],
      "metadata": {
        "id": "step4-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def head_attribution(model, prompt, target_token):\n",
        "    \"\"\"Get per-head attribution.\"\"\"\n",
        "    target_id = model.to_single_token(target_token)\n",
        "    tokens = model.to_tokens(prompt)\n",
        "    logits, cache = model.run_with_cache(tokens)\n",
        "\n",
        "    target_dir = model.W_U[:, target_id]\n",
        "\n",
        "    contributions = {}\n",
        "    for layer in range(model.cfg.n_layers):\n",
        "        # Get per-head outputs (after W_O projection)\n",
        "        # Shape: [batch, seq, n_heads, d_model]\n",
        "        head_results = cache[\"result\", layer][0, -1]  # [n_heads, d_model]\n",
        "\n",
        "        for head in range(model.cfg.n_heads):\n",
        "            head_out = head_results[head]  # [d_model]\n",
        "            contributions[f\"L{layer}H{head}\"] = (head_out @ target_dir).item()\n",
        "\n",
        "    return contributions\n",
        "\n",
        "pos_heads = head_attribution(model, positive_prompt, \" great\")\n",
        "neg_heads = head_attribution(model, negative_prompt, \" great\")\n",
        "\n",
        "# Find heads with biggest difference\n",
        "head_diff = {k: pos_heads[k] - neg_heads[k] for k in pos_heads}\n",
        "sorted_heads = sorted(head_diff.items(), key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "print(\"Top 10 heads by attribution difference:\")\n",
        "print(\"-\" * 50)\n",
        "for head, diff in sorted_heads[:10]:\n",
        "    print(f\"{head}: diff={diff:+.3f}\")"
      ],
      "metadata": {
        "id": "step4-heads"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“ **Write down the top heads.** These are our hypotheses for \"sentiment-reading heads.\" We'll validate them next."
      ],
      "metadata": {
        "id": "step4-note"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 5: Validate with Patching\n",
        "\n",
        "Attribution is correlational. Now we test causation: if we patch the sentiment word's representation from the negative case into the positive case, does the prediction change?"
      ],
      "metadata": {
        "id": "step5-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def patch_position(model, clean_prompt, corrupted_prompt, position, layer):\n",
        "    \"\"\"\n",
        "    Patch the residual stream at a specific position and layer\n",
        "    from corrupted into clean. This is our causal interventionâ€”we're\n",
        "    changing what the model sees mid-computation.\n",
        "    \"\"\"\n",
        "    corrupted_tokens = model.to_tokens(corrupted_prompt)\n",
        "    _, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
        "\n",
        "    # Get the residual stream after this layer processes\n",
        "    # This contains all information the model has built up to this point\n",
        "    corrupted_resid = corrupted_cache[\"resid_post\", layer]\n",
        "\n",
        "    # A hook intercepts and optionally modifies activations during forward pass\n",
        "    # Here we surgically replace just one position's representation\n",
        "    def patch_hook(resid, hook):\n",
        "        resid[:, position, :] = corrupted_resid[:, position, :]\n",
        "        return resid\n",
        "\n",
        "    clean_tokens = model.to_tokens(clean_prompt)\n",
        "\n",
        "    # run_with_hooks executes forward pass but calls our hook at the specified location\n",
        "    patched_logits = model.run_with_hooks(\n",
        "        clean_tokens,\n",
        "        fwd_hooks=[(f\"blocks.{layer}.hook_resid_post\", patch_hook)]\n",
        "    )\n",
        "\n",
        "    return patched_logits"
      ],
      "metadata": {
        "id": "step5-patch-fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find position of \"love\" / \"hate\"\n",
        "pos_tokens = model.to_str_tokens(positive_prompt)\n",
        "print(f\"Tokens: {pos_tokens}\")\n",
        "sentiment_pos = 1  # Usually \"love\" is at position 1 (after \"I\")\n",
        "\n",
        "# Patch at different layers\n",
        "print(\"\\nPatching 'love' â†’ 'hate' at sentiment position:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "clean_logit = get_token_logit(model, positive_prompt, \" great\")\n",
        "print(f\"Original (love â†’ great): {clean_logit:.2f}\")\n",
        "\n",
        "for layer in range(model.cfg.n_layers):\n",
        "    patched = patch_position(model, positive_prompt, negative_prompt, sentiment_pos, layer)\n",
        "    target_id = model.to_single_token(\" great\")\n",
        "    patched_logit = patched[0, -1, target_id].item()\n",
        "    change = patched_logit - clean_logit\n",
        "    print(f\"Layer {layer:2d}: {patched_logit:.2f} (change: {change:+.2f})\")"
      ],
      "metadata": {
        "id": "step5-run-patching"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What to look for**: Layers where patching causes a big drop in \"great\" logit are where the sentiment information is being used."
      ],
      "metadata": {
        "id": "step5-interpretation"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 6: Examine Attention Patterns\n",
        "\n",
        "Let's see what the important heads are attending to."
      ],
      "metadata": {
        "id": "step6-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import circuitsvis as cv\n",
        "from IPython.display import display\n",
        "\n",
        "# Get attention patterns\n",
        "tokens = model.to_tokens(positive_prompt)\n",
        "_, cache = model.run_with_cache(tokens)\n",
        "\n",
        "str_tokens = model.to_str_tokens(positive_prompt)\n",
        "\n",
        "# Pick a head that showed up in attribution (replace with your findings!)\n",
        "important_layer = 8  # Example - use your results\n",
        "important_head = 6   # Example - use your results\n",
        "\n",
        "# Get attention pattern for this head\n",
        "pattern = cache[\"pattern\", important_layer][0, important_head]  # [seq, seq]\n",
        "\n",
        "print(f\"Attention pattern for L{important_layer}H{important_head}\")\n",
        "print(f\"Tokens: {str_tokens}\")\n",
        "\n",
        "# Visualize\n",
        "display(cv.attention.attention_patterns(\n",
        "    attention=cache[\"pattern\", important_layer][0:1],  # [1, n_heads, seq, seq]\n",
        "    tokens=str_tokens,\n",
        "    attention_head_names=[f\"H{h}\" for h in range(model.cfg.n_heads)]\n",
        "))"
      ],
      "metadata": {
        "id": "step6-attention"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What to look for**: Does the final position attend to the sentiment word (\"love\")?"
      ],
      "metadata": {
        "id": "step6-interpretation"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 7: Interpret Your Findings\n",
        "\n",
        "Based on your analysis, answer these questions:\n",
        "\n",
        "1. **Which layers process sentiment?** (Where did patching have the biggest effect?)\n",
        "2. **Which heads are involved?** (Which had the biggest attribution difference?)\n",
        "3. **What are they attending to?** (Do they attend to the sentiment word?)\n",
        "4. **How does the information flow?** (Early layers read sentiment â†’ later layers adjust prediction?)"
      ],
      "metadata": {
        "id": "step7-header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### âœï¸ Write Your Interpretation\n",
        "\n",
        "Before continuing, write 2-3 sentences describing what you found:\n",
        "\n",
        "*Example: \"Layers 7-9 show the biggest patching effect, suggesting sentiment is processed in mid-to-late layers. Head 8.6 has the largest attribution difference and attends strongly to the sentiment word at the final position. This suggests a 'sentiment â†’ adjective' circuit where...\"*\n",
        "\n",
        "**Your interpretation:**\n",
        "\n",
        "(Double-click to edit this cell and write here)"
      ],
      "metadata": {
        "id": "step7-write"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 8: Sanity Checks\n",
        "\n",
        "Before claiming you understand the circuit, verify it generalizes."
      ],
      "metadata": {
        "id": "step8-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Does it generalize to other examples?\n",
        "test_cases = [\n",
        "    (\"I really love this book because it is\", \"positive\"),\n",
        "    (\"I absolutely hate this song because it is\", \"negative\"),\n",
        "    (\"This restaurant is great because the food is\", \"positive\"),\n",
        "    (\"This restaurant is terrible because the food is\", \"negative\"),\n",
        "]\n",
        "\n",
        "print(\"Generalization test:\")\n",
        "for prompt, expected in test_cases:\n",
        "    great_logit = get_token_logit(model, prompt, \" great\")\n",
        "    bad_logit = get_token_logit(model, prompt, \" bad\")\n",
        "    predicted = \"positive\" if great_logit > bad_logit else \"negative\"\n",
        "    match = \"âœ“\" if predicted == expected else \"âœ—\"\n",
        "    print(f\"{match} {expected:8} | great={great_logit:.1f}, bad={bad_logit:.1f} | {prompt[:40]}...\")\n",
        "\n",
        "# 2. What happens without sentiment words?\n",
        "neutral = \"I watched this movie because it is\"\n",
        "print(f\"\\nNeutral case: great={get_token_logit(model, neutral, ' great'):.2f}, bad={get_token_logit(model, neutral, ' bad'):.2f}\")"
      ],
      "metadata": {
        "id": "step8-sanity"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ðŸŽ‰ What You've Learned\n",
        "\n",
        "Congratulations! You've completed a full interpretability analysis. You now know how to:\n",
        "\n",
        "1. âœ… Define and verify a behavior\n",
        "2. âœ… Use logit attribution to find candidate components\n",
        "3. âœ… Validate with activation patching\n",
        "4. âœ… Examine attention patterns\n",
        "5. âœ… Interpret findings and check generalization\n",
        "\n",
        "**The workflow you used**:\n",
        "```\n",
        "Observe behavior â†’ Attribute â†’ Patch â†’ Interpret â†’ Verify\n",
        "```\n",
        "\n",
        "This is the core loop of mechanistic interpretability research."
      ],
      "metadata": {
        "id": "congrats"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## ðŸš€ Try It Yourself\n",
        "\n",
        "Now extend your analysis! Pick one of these variations:"
      ],
      "metadata": {
        "id": "try-it-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRY IT: Different sentiment words\n",
        "# Replace \"love\"/\"hate\" with \"adore\"/\"despise\" - does the same circuit work?\n",
        "\n",
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "try-it-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRY IT: Different behavior entirely\n",
        "# Analyze: \"The capital of France is\" â†’ \"Paris\"\n",
        "# Which components contribute to the factual recall?\n",
        "\n",
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "try-it-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRY IT: Break the behavior\n",
        "# Find an input where the model gets sentiment \"wrong\"\n",
        "# What's different about the attribution?\n",
        "\n",
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "try-it-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Next Steps\n",
        "\n",
        "- **[Running Example](https://ttsugriy.github.io/mechinterp-first-principles/running-example.html)** â€” See all techniques applied to \"Eiffel Tower â†’ Paris\"\n",
        "- **[Exercises](https://ttsugriy.github.io/mechinterp-first-principles/exercises.html)** â€” Practice problems for each technique\n",
        "- **[Chapter 10: Attribution](https://ttsugriy.github.io/mechinterp-first-principles/chapters/10-attribution.html)** â€” Deep dive into attribution methods"
      ],
      "metadata": {
        "id": "next-steps"
      }
    }
  ]
}
